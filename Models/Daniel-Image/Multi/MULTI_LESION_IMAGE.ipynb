{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371cb741-60cc-4194-803e-45f3087da43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "\n",
    "DATASET_PATH = \"data/fgdar\"\n",
    "ENCODER = \"resnet34\"\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 55\n",
    "LR = 5e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "MIN_LR = 1e-6\n",
    "PATIENCE = 6\n",
    "SCHEDULER_PATIENCE = 2\n",
    "LAMBDA = {\"MA\": 1.0, \"HE\": 1.0, \"EX\": 1.0, \"SE\": 1.3}\n",
    "LESION_TYPES = ['MA', 'HE', 'EX', 'SE']\n",
    "LESION_NAMES_FULL = ['Microaneurysm', 'Hemorrhage', 'Hard Exudate', 'Soft Exudate']\n",
    "\n",
    "\n",
    "# Set to True to use your local pretrained weights, or False to use ImageNet\n",
    "USE_CUSTOM_PRETRAINED_WEIGHTS = 0\n",
    "CUSTOM_ENCODER_PATH = \"best_resnet34_fundus_encoder.pth\"\n",
    "\n",
    "\n",
    "\n",
    "# 2. HELPERS, DATASET, AND MODEL\n",
    "def numeric_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]\n",
    "\n",
    "def prepare_fgadr_dataframe(dataset_path):\n",
    "    seg_set_path = os.path.join(dataset_path, 'Seg-set')\n",
    "    original_images_path = os.path.join(seg_set_path, \"Original_Images\")\n",
    "    lesion_paths = {\n",
    "        lesion: os.path.join(seg_set_path, f\"{lesion_name}_Masks\")\n",
    "        for lesion, lesion_name in zip(['MA', 'HE', 'EX', 'SE'], ['Microaneurysms', 'Hemorrhage', 'HardExudate', 'SoftExudate'])\n",
    "    }\n",
    "    image_files = sorted([os.path.join(original_images_path, f) for f in os.listdir(original_images_path)], key=numeric_sort_key)\n",
    "    data = {'image': image_files}\n",
    "    for lesion in LESION_TYPES:\n",
    "        mask_dir = lesion_paths[lesion]\n",
    "        data[f'{lesion}_mask'] = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)], key=numeric_sort_key)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def green_clahe_preprocess(image, clip_limit=2.0, tile_grid_size=(8, 8), blend_alpha=0.75):\n",
    "    green_channel = image[:, :, 1]\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    clahe_green_channel = clahe.apply(green_channel)\n",
    "    clahe_img_3_channel = cv2.cvtColor(clahe_green_channel, cv2.COLOR_GRAY2BGR)\n",
    "    blended_image = cv2.addWeighted(image, 1 - blend_alpha, clahe_img_3_channel, blend_alpha, 0)\n",
    "    return blended_image\n",
    "\n",
    "class FGADRDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = cv2.imread(row['image'])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        masks = []\n",
    "        for lesion in LESION_TYPES:\n",
    "            mask_path = row[f'{lesion}_mask']\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                raise FileNotFoundError(f\"Could not load mask: {mask_path}\")\n",
    "            mask = (mask > 127).astype(np.float32)\n",
    "            masks.append(mask)\n",
    "        masks = np.stack(masks, axis=-1)\n",
    "        processed_image = green_clahe_preprocess(image)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=processed_image.astype(np.uint8), mask=masks)\n",
    "            image = augmented['image']\n",
    "            masks = augmented['mask']\n",
    "        if masks.ndim == 3:\n",
    "            masks = masks.permute(2, 0, 1)\n",
    "        return image, masks\n",
    "\n",
    "class MultiDecoderModel(nn.Module):\n",
    "    def __init__(self, encoder_name=ENCODER, in_channels=3, encoder_weights=\"imagenet\"):\n",
    "        super().__init__()\n",
    "        initial_smp_weights = 'imagenet'\n",
    "        is_custom_weights = isinstance(encoder_weights, str) and os.path.exists(encoder_weights)\n",
    "\n",
    "        if is_custom_weights:\n",
    "            initial_smp_weights = None\n",
    "            print(f\"Initializing encoder '{encoder_name}' architecture (will load custom weights)...\")\n",
    "        else:\n",
    "            print(f\"Initializing encoder '{encoder_name}' with STANDARD '{encoder_weights}' weights.\")\n",
    "\n",
    "        self.encoder = smp.encoders.get_encoder(\n",
    "            name=encoder_name,\n",
    "            in_channels=in_channels,\n",
    "            depth=5,\n",
    "            weights=initial_smp_weights,\n",
    "            output_stride=8\n",
    "        )\n",
    "\n",
    "        if is_custom_weights:\n",
    "            print(f\"Loading CUSTOM weights from file: {encoder_weights}\")\n",
    "            custom_state_dict = torch.load(encoder_weights, map_location='cpu')\n",
    "            self.encoder.load_state_dict(custom_state_dict, strict=False)\n",
    "            print(\"  > Successfully loaded custom pretrained weights into the encoder.\")\n",
    "\n",
    "        # --- Lesion-specific Decoder Heads ---\n",
    "        unet_model_ma = smp.Unet(encoder_name=encoder_name, encoder_output_stride=8, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type='scse', classes=1)\n",
    "        self.ma_decoder, self.ma_head = unet_model_ma.decoder, unet_model_ma.segmentation_head\n",
    "        deeplab_model_he = smp.DeepLabV3Plus(encoder_name=encoder_name, encoder_output_stride=8, decoder_channels=512, decoder_atrous_rates=(6, 12, 18), classes=1)\n",
    "        self.he_decoder, self.he_head = deeplab_model_he.decoder, deeplab_model_he.segmentation_head\n",
    "        unet_model_ex = smp.Unet(encoder_name=encoder_name, encoder_output_stride=8, classes=1)\n",
    "        self.ex_decoder, self.ex_head = unet_model_ex.decoder, unet_model_ex.segmentation_head\n",
    "        deeplab_model_se = smp.DeepLabV3Plus(encoder_name=encoder_name, encoder_output_stride=8, decoder_channels=640, decoder_atrous_rates=(12, 24, 36), classes=1)\n",
    "        self.se_decoder, self.se_head = deeplab_model_se.decoder, deeplab_model_se.segmentation_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        ma_out = self.ma_head(self.ma_decoder(features))\n",
    "        he_out = self.he_head(self.he_decoder(features))\n",
    "        ex_out = self.ex_head(self.ex_decoder(features))\n",
    "        se_out = self.se_head(self.se_decoder(features))\n",
    "        return {'MA': ma_out, 'HE': he_out, 'EX': ex_out, 'SE': se_out}\n",
    "\n",
    "# 3. TRAINING AND EVALUATION UTILITIES\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=True, delta=0, path='checkpoint.pth', mode='max'):\n",
    "        self.patience, self.verbose, self.counter, self.best_score, self.early_stop = patience, verbose, 0, None, False\n",
    "        self.val_metric_best = -float('inf') if mode == 'max' else float('inf')\n",
    "        self.delta, self.path, self.mode = delta, path, mode\n",
    "\n",
    "    def __call__(self, val_metric, model):\n",
    "        score = val_metric\n",
    "        if self.best_score is None or \\\n",
    "           (self.mode == 'max' and score > self.best_score + self.delta) or \\\n",
    "           (self.mode == 'min' and score < self.best_score - self.delta):\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_metric, model)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose: print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, val_metric, model):\n",
    "        if self.verbose: print(f'Validation metric improved ({self.val_metric_best:.6f} --> {val_metric:.6f}). Saving model to {self.path}...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_metric_best = val_metric\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, epsilon=1e-7):\n",
    "    # Ensure inputs are binary\n",
    "    y_true_bin = (y_true > 0.5).float()\n",
    "    y_pred_bin = (y_pred > 0.5).float()\n",
    "\n",
    "    tp = torch.sum(y_true_bin * y_pred_bin)\n",
    "    fp = torch.sum((1 - y_true_bin) * y_pred_bin)\n",
    "    fn = torch.sum(y_true_bin * (1 - y_pred_bin))\n",
    "\n",
    "    dice = (2. * tp + epsilon) / (2 * tp + fp + fn + epsilon)\n",
    "    iou = (tp + epsilon) / (tp + fp + fn + epsilon)\n",
    "    sensitivity = (tp + epsilon) / (tp + fn + epsilon) \n",
    "    precision = (tp + epsilon) / (tp + fp + epsilon)\n",
    "\n",
    "    return dice.item(), iou.item(), sensitivity.item(), precision.item()\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.5, gamma=4/3, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.alpha, self.beta, self.gamma, self.eps = alpha, beta, gamma, eps\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        tp = torch.sum(targets * inputs)\n",
    "        fp = torch.sum((1 - targets) * inputs)\n",
    "        fn = torch.sum(targets * (1 - inputs))\n",
    "        tversky = (tp + self.eps) / (tp + self.alpha * fn + self.beta * fp + self.eps)\n",
    "        return torch.pow((1 - tversky), self.gamma)\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, ft_alpha=0.5, ft_beta=0.5, ft_gamma=4/3, bce_weight=0.05):\n",
    "        super().__init__()\n",
    "        self.focal_tversky = FocalTverskyLoss(alpha=ft_alpha, beta=ft_beta, gamma=ft_gamma)\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.bce_weight = bce_weight\n",
    "    def forward(self, inputs, targets):\n",
    "        return self.focal_tversky(inputs, targets) + self.bce_weight * self.bce(inputs, targets)\n",
    "\n",
    "\n",
    "def evaluate_on_test_set(model, test_loader, device):\n",
    "    print(\"\\n--- Evaluating model on the test set ---\")\n",
    "    model.eval()\n",
    "    \n",
    "    # Store lists of scores for each lesion type\n",
    "    test_scores = {lesion: {'dice': [], 'iou': [], 'sensitivity': [], 'precision': []} for lesion in LESION_TYPES}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            predictions = model(images)\n",
    "            \n",
    "            for lesion in LESION_TYPES:\n",
    "                li = LESION_TYPES.index(lesion)\n",
    "                pred_prob = torch.sigmoid(predictions[lesion])\n",
    "                true_mask = masks[:, li:li+1]\n",
    "\n",
    "                # Calculate metrics for this batch item\n",
    "                dice, iou, sensitivity, precision = calculate_metrics(true_mask, pred_prob)\n",
    "                \n",
    "                # Append scores\n",
    "                test_scores[lesion]['dice'].append(dice)\n",
    "                test_scores[lesion]['iou'].append(iou)\n",
    "                test_scores[lesion]['sensitivity'].append(sensitivity)\n",
    "                test_scores[lesion]['precision'].append(precision)\n",
    "    \n",
    "    # Calculate and print average scores\n",
    "    print(\"\\n--- Test Set Evaluation Results ---\")\n",
    "    print(f\"{'Lesion':<15} | {'Dice':<10} | {'IoU':<10} | {'Sensitivity':<12} | {'Precision':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "    for lesion, metrics in test_scores.items():\n",
    "        avg_dice = np.mean(metrics['dice'])\n",
    "        avg_iou = np.mean(metrics['iou'])\n",
    "        avg_sensitivity = np.mean(metrics['sensitivity'])\n",
    "        avg_precision = np.mean(metrics['precision'])\n",
    "        print(f\"{lesion:<15} | {avg_dice:<10.4f} | {avg_iou:<10.4f} | {avg_sensitivity:<12.4f} | {avg_precision:<10.4f}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "\n",
    "# 4. MAIN EXECUTION\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    df = prepare_fgadr_dataframe(DATASET_PATH)\n",
    "    train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=(0.15/0.85), random_state=42)\n",
    "    print(f\"Dataset split: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n",
    "\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=IMG_SIZE, width=IMG_SIZE), A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.1),\n",
    "        A.Rotate(limit=10, p=0.5, border_mode=cv2.BORDER_CONSTANT), A.Normalize(), ToTensorV2(),\n",
    "    ])\n",
    "    val_test_transform = A.Compose([A.Resize(height=IMG_SIZE, width=IMG_SIZE), A.Normalize(), ToTensorV2()])\n",
    "\n",
    "    train_dataset = FGADRDataset(train_df, transform=train_transform)\n",
    "    val_dataset = FGADRDataset(val_df, transform=val_test_transform)\n",
    "    test_dataset = FGADRDataset(test_df, transform=val_test_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    # Using batch size of 1 for test loader for per-image evaluation\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    if USE_CUSTOM_PRETRAINED_WEIGHTS:\n",
    "        print(\"\\n--- CONFIG: Using CUSTOM Pretrained Encoder ---\")\n",
    "        encoder_weights_source, model_save_path = CUSTOM_ENCODER_PATH, 'custom_model.pth'\n",
    "    else:\n",
    "        print(\"\\n--- CONFIG: Using standard IMAGENET Encoder ---\")\n",
    "        encoder_weights_source, model_save_path = \"imagenet\", 'imagenet_model.pth'\n",
    "\n",
    "    model = MultiDecoderModel(encoder_weights=encoder_weights_source).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, betas=(0.9, 0.999), eps=1e-8)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=SCHEDULER_PATIENCE, min_lr=MIN_LR)\n",
    "    early_stopper = EarlyStopping(patience=PATIENCE, verbose=True, path=model_save_path, delta=0.002, mode='max')\n",
    "    criterion = CombinedLoss()\n",
    "\n",
    "    print(f\"\\nStarting training (Model will be saved to: {model_save_path})...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss, train_dice_scores = 0, []\n",
    "        for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(images)\n",
    "            loss, batch_dices_train = 0, []\n",
    "            for lesion in predictions:\n",
    "                lesion_idx = LESION_TYPES.index(lesion)\n",
    "                target_mask = masks[:, lesion_idx:lesion_idx+1]\n",
    "                loss += criterion(predictions[lesion], target_mask) * LAMBDA[lesion]\n",
    "                # We only need dice for the training loop printout\n",
    "                dice, _, _, _ = calculate_metrics(target_mask, torch.sigmoid(predictions[lesion]))\n",
    "                batch_dices_train.append(dice)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_dice_scores.append(np.mean(batch_dices_train))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_dice_scores = 0, []\n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\"):\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                predictions = model(images)\n",
    "                loss, batch_dices = 0, []\n",
    "                for lesion in predictions:\n",
    "                    lesion_idx = LESION_TYPES.index(lesion)\n",
    "                    target_mask = masks[:, lesion_idx:lesion_idx+1]\n",
    "                    loss += criterion(predictions[lesion], target_mask) * LAMBDA[lesion]\n",
    "                    dice, _, _, _ = calculate_metrics(target_mask, torch.sigmoid(predictions[lesion]))\n",
    "                    batch_dices.append(dice)\n",
    "                val_loss += loss.item()\n",
    "                val_dice_scores.append(np.mean(batch_dices))\n",
    "\n",
    "        avg_train_loss, avg_train_dice = train_loss / len(train_loader), np.mean(train_dice_scores)\n",
    "        avg_val_loss, avg_val_dice = val_loss / len(val_loader), np.mean(val_dice_scores)\n",
    "        print(f\"Epoch {epoch+1:03d}: Train Loss={avg_train_loss:.4f} | Train Dice={avg_train_dice:.4f} | Val Loss={avg_val_loss:.4f} | Val Dice={avg_val_dice:.4f}\")\n",
    "        \n",
    "        scheduler.step(avg_val_dice)\n",
    "        early_stopper(avg_val_dice, model)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Early stopping triggered.\"); break\n",
    "\n",
    "    print(f\"\\n--- Training Finished ---\\nLoading best model for final evaluation from {model_save_path}...\")\n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    \n",
    "    evaluate_on_test_set(model, test_loader, device)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1da306-0975-4309-8985-7dd3f771cd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
