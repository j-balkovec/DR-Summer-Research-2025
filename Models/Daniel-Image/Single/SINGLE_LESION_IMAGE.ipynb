{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc82ddf-de44-41d0-8179-da92f3f1a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================\n",
    "# Config & Hyperparameters\n",
    "# =============================\n",
    "DATASET_PATH = \"data/fgdar\"\n",
    "TARGET_LESION = 'HE'\n",
    "\n",
    "# --- Experiment Settings ---\n",
    "ENCODER = \"resnet34\"\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 1\n",
    "ACCUMULATION_STEPS = 4\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "MIN_LR = 1e-6\n",
    "PATIENCE = 8\n",
    "SCHEDULER_PATIENCE = 2\n",
    "EPOCHS = 55\n",
    "EMA_DECAY = 0.999\n",
    "LOSS_BCE_ALPHA = 0.05\n",
    "# --- Post-processing threshold ---\n",
    "MIN_LESION_AREA = 24\n",
    "\n",
    "LESION_MAP = {\n",
    "    'MA': 'Microaneurysms',\n",
    "    'HE': 'Hemorrhage',\n",
    "    'EX': 'HardExudate',\n",
    "    'SE': 'SoftExudate'\n",
    "}\n",
    "LESION_FULL_NAME = LESION_MAP[TARGET_LESION].replace('Exudate', ' Exudate')\n",
    "\n",
    "# --- Pre-defined Thresholds ---\n",
    "LESION_THRESHOLDS = {\n",
    "    'MA': 0.30,\n",
    "    'HE': 0.45,\n",
    "    'EX': 0.45,\n",
    "    'SE': 0.45\n",
    "}\n",
    "\n",
    "# =============================\n",
    "# Helpers & Post-Processing\n",
    "# =============================\n",
    "def numeric_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]\n",
    "\n",
    "def post_process_mask(mask_np, min_area):\n",
    "    if mask_np.dtype != np.uint8:\n",
    "        mask_np = (mask_np * 255).astype(np.uint8)\n",
    "    \n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask_np, connectivity=8)\n",
    "    processed_mask = np.zeros_like(mask_np)\n",
    "    \n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            processed_mask[labels == i] = 255\n",
    "            \n",
    "    return (processed_mask / 255).astype(np.float32)\n",
    "\n",
    "\n",
    "def prepare_fgadr_dataframe(dataset_path):\n",
    "    seg_set_path = os.path.join(dataset_path, 'Seg-set')\n",
    "    original_images_path = os.path.join(seg_set_path, \"Original_Images\")\n",
    "    lesion_paths = {\n",
    "        lesion: os.path.join(seg_set_path, f\"{name}_Masks\")\n",
    "        for lesion, name in LESION_MAP.items()\n",
    "    }\n",
    "    image_files = sorted([os.path.join(original_images_path, f) for f in os.listdir(original_images_path)], key=numeric_sort_key)\n",
    "    data = {'image': image_files}\n",
    "    for lesion_code in LESION_MAP.keys():\n",
    "        mask_dir = lesion_paths[lesion_code]\n",
    "        data[f'{lesion_code}_mask'] = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)], key=numeric_sort_key)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def green_clahe_preprocess(image, clip_limit=2.0, tile_grid_size=(8, 8), blend_alpha=0.75):\n",
    "    green_channel = image[:, :, 1]\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    clahe_green_channel = clahe.apply(green_channel)\n",
    "    clahe_img_3_channel = cv2.cvtColor(clahe_green_channel, cv2.COLOR_GRAY2BGR)\n",
    "    blended_image = cv2.addWeighted(image, 1 - blend_alpha, clahe_img_3_channel, blend_alpha, 0)\n",
    "    return blended_image\n",
    "\n",
    "class FGADRDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_lesion, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "        self.target_lesion = target_lesion\n",
    "        self.mask_column = f'{self.target_lesion}_mask'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = cv2.imread(row['image'])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask_path = row[self.mask_column]\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise FileNotFoundError(f\"Could not load mask: {mask_path}\")\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "        processed_image = green_clahe_preprocess(image)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=processed_image.astype(np.uint8), mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        if mask.ndim == 2:\n",
    "            mask = mask.unsqueeze(0)\n",
    "        return image, mask\n",
    "\n",
    "# =============================\n",
    "# Model (Unet++ with ResNet34)\n",
    "# =============================\n",
    "class SingleLesionModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder_name=ENCODER,\n",
    "                 in_channels=3,\n",
    "                 target_lesion=TARGET_LESION):\n",
    "        super().__init__()\n",
    "        print(f\"Initializing Unet++ model for {target_lesion} with encoder {encoder_name}\")\n",
    "        self.model = smp.UnetPlusPlus(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=in_channels,\n",
    "            classes=1,\n",
    "            activation=None,\n",
    "            attention_type='scse'\n",
    "        )\n",
    "        \n",
    "        # Add sensitivity-focused refinement\n",
    "        self.sensitivity_head = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 1, 1),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_pred = self.model(x)\n",
    "        sensitivity_boost = self.sensitivity_head(torch.sigmoid(base_pred))\n",
    "        return base_pred + 0.5 * sensitivity_boost  # Boost positive predictions\n",
    "\n",
    "# =============================\n",
    "# Training Utils\n",
    "# =============================\n",
    "class EMA:\n",
    "    def __init__(self, model, decay):\n",
    "        self.decay = decay\n",
    "        self.shadow = {name: param.data.clone() for name, param in model.named_parameters() if param.requires_grad}\n",
    "        self.backup = {}\n",
    "\n",
    "    def update(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def apply_shadow(self, model):\n",
    "        self.backup = model.state_dict()\n",
    "        model.load_state_dict(self.shadow, strict=False)\n",
    "\n",
    "    def restore(self, model):\n",
    "        model.load_state_dict(self.backup, strict=True)\n",
    "        self.backup = {}\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=True, delta=0, path='checkpoint.pth', mode='max', ema=None):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_metric_best = -float('inf') if mode == 'max' else float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.mode = mode\n",
    "        self.ema = ema\n",
    "\n",
    "    def __call__(self, val_metric, model):\n",
    "        score = val_metric\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_metric, model)\n",
    "        elif (self.mode == 'max' and score < self.best_score + self.delta) or \\\n",
    "             (self.mode == 'min' and score > self.best_score - self.delta):\n",
    "            self.counter += 1\n",
    "            if self.verbose: print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_metric, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_metric, model):\n",
    "        if self.verbose: \n",
    "            print(f'Validation metric improved ({self.val_metric_best:.6f} --> {val_metric:.6f}). Saving model...')\n",
    "        \n",
    "        if self.ema:\n",
    "            self.ema.apply_shadow(model)\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            self.ema.restore(model)\n",
    "        else:\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            \n",
    "        self.val_metric_best = val_metric\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, epsilon=1e-7):\n",
    "    y_true = (y_true > 0.5).float()\n",
    "    y_pred = (y_pred > 0.5).float()\n",
    "    tp = torch.sum(y_true * y_pred)\n",
    "    fp = torch.sum((1 - y_true) * y_pred)\n",
    "    fn = torch.sum(y_true * (1 - y_pred))\n",
    "    dice = (2. * tp + epsilon) / (2 * tp + fp + fn + epsilon)\n",
    "    iou = (tp + epsilon) / (tp + fp + fn + epsilon)\n",
    "    sensitivity = (tp + epsilon) / (tp + fn + epsilon)\n",
    "    precision = (tp + epsilon) / (tp + fp + epsilon)\n",
    "    return dice.item(), iou.item(), sensitivity.item(), precision.item()\n",
    "\n",
    "# =============================\n",
    "# Loss Functions\n",
    "# =============================\n",
    "class SensitivityOptimizedLoss(nn.Module):\n",
    "    \"\"\"Loss function specifically designed to combat overly conservative predictions\"\"\"\n",
    "    def __init__(self, alpha=0.8, beta=0.2, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # Heavy penalty for missing lesions (False Negatives)\n",
    "        self.beta = beta    # Light penalty for false alarms (False Positives)\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        inputs_sigmoid = torch.sigmoid(inputs)\n",
    "        \n",
    "        tp = torch.sum(targets * inputs_sigmoid)\n",
    "        fn = torch.sum(targets * (1 - inputs_sigmoid))  # Missing true lesions\n",
    "        fp = torch.sum((1 - targets) * inputs_sigmoid)  # False alarms\n",
    "        \n",
    "        tversky_index = tp / (tp + self.alpha * fn + self.beta * fp + 1e-7)\n",
    "        tversky_loss = (1 - tversky_index) ** self.gamma\n",
    "        \n",
    "        # Extra penalty for completely missing lesion-containing images\n",
    "        has_lesion = torch.sum(targets) > 0\n",
    "        has_prediction = torch.sum(inputs_sigmoid > 0.2) > 0\n",
    "        \n",
    "        if has_lesion and not has_prediction:\n",
    "            missing_penalty = torch.tensor(3.0, device=inputs.device)\n",
    "        else:\n",
    "            missing_penalty = torch.tensor(0.0, device=inputs.device)\n",
    "            \n",
    "        return tversky_loss + missing_penalty\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.5, gamma=4/3, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        tp = torch.sum(targets * inputs)\n",
    "        fp = torch.sum((1 - targets) * inputs)\n",
    "        fn = torch.sum(targets * (1 - inputs))\n",
    "        tversky = (tp + self.eps) / (tp + self.alpha * fn + self.beta * fp + self.eps)\n",
    "        loss = torch.pow((1 - tversky), self.gamma)\n",
    "        return loss\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, bce_alpha=LOSS_BCE_ALPHA):\n",
    "        super().__init__()\n",
    "        self.focal_tversky = FocalTverskyLoss()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.alpha = bce_alpha\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ft_loss = self.focal_tversky(inputs, targets)\n",
    "        bce_loss = self.bce(inputs, targets)\n",
    "        return ft_loss + self.alpha * bce_loss\n",
    "\n",
    "# =============================\n",
    "# Main Execution\n",
    "# =============================\n",
    "def main():\n",
    "    OUTPUT_DIR = f\"analysis_{TARGET_LESION}\"\n",
    "    if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, \"worst_cases\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, \"best_cases\"), exist_ok=True)\n",
    "    print(f\"Analysis files will be saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"--- Training Unet++ model for {LESION_FULL_NAME} ({TARGET_LESION}) ---\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    df = prepare_fgadr_dataframe(DATASET_PATH)\n",
    "    # This split creates a 70% train, 15% validation, and 15% test set\n",
    "    train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=(0.15/0.85), random_state=42)\n",
    "    \n",
    "    # --- MODIFIED: Curate TRAINING DATA ONLY for a 70:30 positive:negative split ---\n",
    "    print(\"\\nCurating training dataset for a 70:30 positive:negative split...\")\n",
    "    mask_col = f'{TARGET_LESION}_mask'\n",
    "    train_df['has_lesion'] = train_df[mask_col].apply(lambda p: cv2.imread(p, 0).max() > 0)\n",
    "    \n",
    "    positive_df = train_df[train_df['has_lesion']].copy()\n",
    "    negative_df = train_df[~train_df['has_lesion']].copy()\n",
    "    \n",
    "    num_pos_available = len(positive_df)\n",
    "    num_neg_available = len(negative_df)\n",
    "    print(f\"Found {num_pos_available} positive samples and {num_neg_available} negative samples in the original training set.\")\n",
    "\n",
    "    # Determine the limiting factor to maintain the 70:30 ratio.\n",
    "    # If we keep all positive samples, we need num_pos_available * (30/70) negative samples.\n",
    "    # If we keep all negative samples, we need num_neg_available * (70/30) positive samples.\n",
    "    required_neg_for_ratio = int(round(num_pos_available * (30.0 / 70.0)))\n",
    "    required_pos_for_ratio = int(round(num_neg_available * (70.0 / 30.0)))\n",
    "\n",
    "    if required_neg_for_ratio <= num_neg_available:\n",
    "        # We have enough negative samples to match all positive samples.\n",
    "        print(f\"Using all {num_pos_available} positive samples.\")\n",
    "        negative_subset_df = negative_df.sample(n=required_neg_for_ratio, random_state=42)\n",
    "        print(f\"Sampling {len(negative_subset_df)} negative samples to achieve a 70:30 ratio.\")\n",
    "        train_df = pd.concat([positive_df, negative_subset_df])\n",
    "    else:\n",
    "        # We don't have enough negative samples. Use all available negatives and downsample positives.\n",
    "        print(f\"Not enough negative samples. Using all {num_neg_available} negative samples.\")\n",
    "        positive_subset_df = positive_df.sample(n=required_pos_for_ratio, random_state=42)\n",
    "        print(f\"Downsampling to {len(positive_subset_df)} positive samples to achieve a 70:30 ratio.\")\n",
    "        train_df = pd.concat([positive_subset_df, negative_df])\n",
    "\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    final_pos = train_df['has_lesion'].sum()\n",
    "    final_total = len(train_df)\n",
    "    print(f\"New curated training set size: {final_total} images.\")\n",
    "    if final_total > 0:\n",
    "        pos_perc = final_pos / final_total\n",
    "        neg_perc = (final_total - final_pos) / final_total\n",
    "        print(f\"Final split: {final_pos} positive ({pos_perc:.2%}), {final_total - final_pos} negative ({neg_perc:.2%}).\\n\")\n",
    "\n",
    "    # Save split summary for analysis\n",
    "    split_summary = []\n",
    "    splits = {'train': train_df, 'val': val_df, 'test': test_df}\n",
    "    for name, split_df in splits.items():\n",
    "        n = len(split_df)\n",
    "        # For val/test, need to check for has_lesion as it wasn't pre-calculated\n",
    "        if 'has_lesion' not in split_df.columns:\n",
    "            lesion_positive_count = split_df[mask_col].apply(lambda p: cv2.imread(p, 0).max() > 0).sum()\n",
    "        else:\n",
    "            lesion_positive_count = split_df['has_lesion'].sum()\n",
    "        lesion_rate = lesion_positive_count / n if n > 0 else 0\n",
    "        split_summary.append({'name': name, 'n': n, 'counts': lesion_positive_count, 'rate': lesion_rate})\n",
    "    pd.DataFrame(split_summary).to_csv(os.path.join(OUTPUT_DIR, 'split_summary.csv'), index=False)\n",
    "\n",
    "\n",
    "    positive_count = train_df['has_lesion'].sum()\n",
    "    negative_count = len(train_df) - positive_count\n",
    "    weights = [1.0 / positive_count if has_lesion else 1.0 / negative_count \n",
    "               for has_lesion in train_df['has_lesion']]\n",
    "    sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "    \n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=IMG_SIZE, width=IMG_SIZE), A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.1),\n",
    "        A.Rotate(limit=10, p=0.5, border_mode=cv2.BORDER_CONSTANT), A.Normalize(), ToTensorV2(),\n",
    "    ])\n",
    "    val_test_transform = A.Compose([A.Resize(height=IMG_SIZE, width=IMG_SIZE), A.Normalize(), ToTensorV2()])\n",
    "\n",
    "    train_dataset = FGADRDataset(train_df, target_lesion=TARGET_LESION, transform=train_transform)\n",
    "    val_dataset = FGADRDataset(val_df, target_lesion=TARGET_LESION, transform=val_test_transform)\n",
    "    test_dataset = FGADRDataset(test_df, target_lesion=TARGET_LESION, transform=val_test_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    model = SingleLesionModel().to(device)\n",
    "    model_save_path = f'model_{TARGET_LESION}_UnetPP_{ENCODER}.pth'\n",
    "\n",
    "    encoder_params = model.model.encoder.parameters()\n",
    "    decoder_params = [p for n, p in model.named_parameters() if 'encoder' not in n]\n",
    "    optimizer_params = [\n",
    "        {'params': encoder_params, 'lr': LR},\n",
    "        {'params': decoder_params, 'lr': LR * 10}\n",
    "    ]\n",
    "    optimizer = torch.optim.AdamW(optimizer_params, weight_decay=WEIGHT_DECAY, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=SCHEDULER_PATIENCE, min_lr=MIN_LR)\n",
    "    \n",
    "    criterion = SensitivityOptimizedLoss(alpha=0.8, beta=0.2, gamma=2.0)\n",
    "    print(\"Using SensitivityOptimizedLoss to improve recall and reduce overly conservative predictions\")\n",
    "    \n",
    "    scaler = GradScaler(enabled=device.type == 'cuda')\n",
    "    ema = EMA(model, decay=EMA_DECAY) if EMA_DECAY > 0 else None\n",
    "    early_stopper = EarlyStopping(patience=PATIENCE, verbose=True, path=model_save_path, delta=0.002, mode='max', ema=ema)\n",
    "\n",
    "    training_history = []\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        for i, (images, masks) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            with autocast(enabled=device.type == 'cuda'):\n",
    "                predictions = model(images)\n",
    "                loss = criterion(predictions, masks)\n",
    "                loss = loss / ACCUMULATION_STEPS\n",
    "            scaler.scale(loss).backward()\n",
    "            if (i + 1) % ACCUMULATION_STEPS == 0 or (i + 1) == len(train_loader):\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                if ema: ema.update(model)\n",
    "            train_loss += loss.item() * ACCUMULATION_STEPS\n",
    "\n",
    "        if ema: ema.apply_shadow(model)\n",
    "        model.eval()\n",
    "        val_loss, val_dice_scores = 0, []\n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\"):\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                with autocast(enabled=device.type == 'cuda'):\n",
    "                    predictions = model(images)\n",
    "                    loss = criterion(predictions, masks)\n",
    "                val_loss += loss.item()\n",
    "                dice, _, _, _ = calculate_metrics(masks, torch.sigmoid(predictions))\n",
    "                val_dice_scores.append(dice)\n",
    "        if ema: ema.restore(model)\n",
    "        \n",
    "        avg_train_loss, avg_val_loss, avg_val_dice = train_loss / len(train_loader), val_loss / len(val_loader), np.mean(val_dice_scores)\n",
    "        print(f\"Epoch {epoch+1:03d}: Train Loss={avg_train_loss:.4f} | Val Loss={avg_val_loss:.4f} Dice (EMA)={avg_val_dice:.4f}\")\n",
    "        training_history.append({'epoch': epoch + 1, 'train_loss': avg_train_loss, 'val_loss': avg_val_loss, 'val_dice': avg_val_dice})\n",
    "        \n",
    "        scheduler.step(avg_val_dice)\n",
    "        early_stopper(avg_val_dice, model)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "            \n",
    "    pd.DataFrame(training_history).to_csv(os.path.join(OUTPUT_DIR, 'metrics.csv'), index=False)\n",
    "    print(\"Saved epoch-wise metrics.\")\n",
    "\n",
    "    print(f\"\\n--- Training Finished ---\\nLoading best model from {model_save_path} for final evaluation...\")\n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # --- Use pre-defined threshold instead of tuning ---\n",
    "    best_thr = LESION_THRESHOLDS[TARGET_LESION]\n",
    "    print(f\"Using pre-defined threshold for {TARGET_LESION}: {best_thr:.4f}\")\n",
    "\n",
    "    per_image_metrics = []\n",
    "    worst_cases, best_cases = [], []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(tqdm(test_loader, desc=\"Evaluating on Test Set\")):\n",
    "            image_id = os.path.basename(test_df.iloc[i]['image']).replace('.png', '')\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            with autocast(enabled=device.type == 'cuda'):\n",
    "                predictions = model(images)\n",
    "            prob = torch.sigmoid(predictions)\n",
    "            bin_mask_tensor = (prob > best_thr).float()\n",
    "            \n",
    "            bin_mask_np = bin_mask_tensor.squeeze().cpu().numpy()\n",
    "            processed_mask_np = post_process_mask(bin_mask_np, min_area=MIN_LESION_AREA)\n",
    "            processed_mask_tensor = torch.from_numpy(processed_mask_np).unsqueeze(0).to(device)\n",
    "            \n",
    "            gt_pixels = torch.sum(masks).item()\n",
    "            pred_pixels = torch.sum(processed_mask_tensor).item()\n",
    "            \n",
    "            dice, iou, recall, precision = calculate_metrics(masks, processed_mask_tensor)\n",
    "            per_image_metrics.append({\n",
    "                'image_id': image_id, 'dice': dice, 'iou': iou,\n",
    "                'recall': recall, 'precision': precision,\n",
    "                'gt_pixels': gt_pixels, 'pred_pixels': pred_pixels\n",
    "            })\n",
    "            \n",
    "            case_data = (dice, image_id, images.cpu(), masks.cpu(), processed_mask_tensor.cpu())\n",
    "            if len(worst_cases) < 5 or dice < worst_cases[-1][0]:\n",
    "                worst_cases = sorted(worst_cases + [case_data], key=lambda x: x[0])[:5]\n",
    "            if len(best_cases) < 5 or dice > best_cases[-1][0]:\n",
    "                best_cases = sorted(best_cases + [case_data], key=lambda x: x[0], reverse=True)[:5]\n",
    "\n",
    "    pd.DataFrame(per_image_metrics).to_csv(os.path.join(OUTPUT_DIR, 'per_image_test_metrics.csv'), index=False)\n",
    "    print(\"Saved per-image test metrics.\")\n",
    "    \n",
    "    def save_panel(case_data, folder):\n",
    "        dice, img_id, img, gt_mask, pred_mask = case_data\n",
    "        mean, std = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1), torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        img = torch.clamp(img.squeeze(0) * std + mean, 0, 1)\n",
    "        gt_overlay, pred_overlay = img.clone(), img.clone()\n",
    "        gt_overlay[1, :, :] = torch.max(gt_overlay[1, :, :], gt_mask.squeeze(0))\n",
    "        pred_overlay[0, :, :] = torch.max(pred_overlay[0, :, :], pred_mask.squeeze(0))\n",
    "        panel = torch.cat([img, gt_overlay, pred_overlay], dim=2)\n",
    "        save_image(panel, os.path.join(folder, f\"{img_id}_dice{dice:.4f}.png\"))\n",
    "\n",
    "    for case in worst_cases: save_panel(case, os.path.join(OUTPUT_DIR, \"worst_cases\"))\n",
    "    for case in best_cases: save_panel(case, os.path.join(OUTPUT_DIR, \"best_cases\"))\n",
    "    print(\"Saved best and worst case image panels.\")\n",
    "        \n",
    "    avg_metrics = pd.DataFrame(per_image_metrics)[['dice', 'iou', 'recall', 'precision']].mean()\n",
    "    print(f\"\\n--- Performance Metrics for {LESION_FULL_NAME} on Test Set (Post-Processing) ---\")\n",
    "    print(f\"  - Dice: {avg_metrics['dice']:.4f}\")\n",
    "    print(f\"  - IoU: {avg_metrics['iou']:.4f}\")\n",
    "    print(f\"  - Sensitivity (Recall): {avg_metrics['recall']:.4f}\")\n",
    "    print(f\"  - Precision: {avg_metrics['precision']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e444b-c2d2-473b-9ec7-67f0146d6428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
